{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "project_description",
            "metadata": {},
            "source": [
                "# Project Description\n",
                "\n",
                "Beta Bank customers are leaving, little by little, every month. The bankers discovered that it is cheaper to save existing customers than to attract new ones.\n",
                "\n",
                "**Objective**\n",
                "The goal of this project is to predict whether a customer will leave the bank in the near future. We analyze historical data on customer behavior and contract termination to identify patterns associated with churn.\n",
                "\n",
                "**Methodology**\n",
                "We develop and evaluate multiple machine learning models (Decision Tree, Random Forest, Logistic Regression). \n",
                "To ensure robust evaluation and avoid overfitting, we employ a **Train/Validation/Test split (60/20/20)**. Hyperparameters are tuned manually using loops on the Validation set, and the final model is evaluated on the Test set.\n",
                "To address class imbalance, we compare **Baseline** (no sampling), **Upsampling**, and **Downsampling** techniques applied strictly to the training data.\n",
                "\n",
                "**Success Criteria**\n",
                "The primary performance metric is the **F1 score**, with a target of at least **0.59** on the test set. We also evaluate the **AUC-ROC** metric."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1c3f7f73",
            "metadata": {},
            "source": [
                "# 1. Packages\n",
                "Updated to remove `GridSearchCV` and `Pipeline` imports, as we are implementing manual loops and scaling."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "id": "e3eb9c16",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.tree import DecisionTreeClassifier \n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import f1_score, roc_auc_score\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.utils import resample"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6be1846d",
            "metadata": {},
            "source": [
                "# 2. Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "id": "2a833e9f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 10000 entries, 0 to 9999\n",
                        "Data columns (total 11 columns):\n",
                        " #   Column           Non-Null Count  Dtype  \n",
                        "---  ------           --------------  -----  \n",
                        " 0   creditscore      10000 non-null  int64  \n",
                        " 1   geography        10000 non-null  object \n",
                        " 2   gender           10000 non-null  object \n",
                        " 3   age              10000 non-null  int64  \n",
                        " 4   tenure           9091 non-null   float64\n",
                        " 5   balance          10000 non-null  float64\n",
                        " 6   numofproducts    10000 non-null  int64  \n",
                        " 7   hascrcard        10000 non-null  int64  \n",
                        " 8   isactivemember   10000 non-null  int64  \n",
                        " 9   estimatedsalary  10000 non-null  float64\n",
                        " 10  exited           10000 non-null  int64  \n",
                        "dtypes: float64(3), int64(6), object(2)\n",
                        "memory usage: 859.5+ KB\n",
                        "None\n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv(r'C:\\Users\\valen\\OneDrive\\Escritorio\\Juano_VS\\Beta-Bank\\Data\\Churn.csv')\n",
                "df.columns = df.columns.str.lower()\n",
                "df = df.drop(['rownumber', 'customerid', 'surname'], axis=1)\n",
                "print(df.info())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 142,
            "id": "20583958",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(382, 11)"
                        ]
                    },
                    "execution_count": 142,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Check for the existence of values equal to 0.\n",
                "# We do this to see if missing values could be replaced by 0 (if there weren't entries already with this value).\n",
                "df[df['tenure']==0].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 143,
            "id": "7c322b16",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "5.0\n"
                    ]
                }
            ],
            "source": [
                "median = df['tenure'].median()\n",
                "print(median)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "id": "f4d9c4a7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 10000 entries, 0 to 9999\n",
                        "Data columns (total 11 columns):\n",
                        " #   Column           Non-Null Count  Dtype  \n",
                        "---  ------           --------------  -----  \n",
                        " 0   creditscore      10000 non-null  int64  \n",
                        " 1   geography        10000 non-null  object \n",
                        " 2   gender           10000 non-null  object \n",
                        " 3   age              10000 non-null  int64  \n",
                        " 4   tenure           10000 non-null  float64\n",
                        " 5   balance          10000 non-null  float64\n",
                        " 6   numofproducts    10000 non-null  int64  \n",
                        " 7   hascrcard        10000 non-null  int64  \n",
                        " 8   isactivemember   10000 non-null  int64  \n",
                        " 9   estimatedsalary  10000 non-null  float64\n",
                        " 10  exited           10000 non-null  int64  \n",
                        "dtypes: float64(3), int64(6), object(2)\n",
                        "memory usage: 859.5+ KB\n"
                    ]
                }
            ],
            "source": [
                "# Replace missing values with the median value of the column\n",
                "df['tenure'] = df['tenure'].fillna(median)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 145,
            "id": "a56d81aa",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0\n"
                    ]
                }
            ],
            "source": [
                "# Check for duplicates\n",
                "print(df.duplicated().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 146,
            "id": "aaf7698d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>creditscore</th>\n",
                            "      <th>age</th>\n",
                            "      <th>tenure</th>\n",
                            "      <th>balance</th>\n",
                            "      <th>numofproducts</th>\n",
                            "      <th>hascrcard</th>\n",
                            "      <th>isactivemember</th>\n",
                            "      <th>estimatedsalary</th>\n",
                            "      <th>exited</th>\n",
                            "      <th>geography_Germany</th>\n",
                            "      <th>geography_Spain</th>\n",
                            "      <th>gender_Male</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>619</td>\n",
                            "      <td>42</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>101348.88</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>608</td>\n",
                            "      <td>41</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>83807.86</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>112542.58</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>502</td>\n",
                            "      <td>42</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>159660.80</td>\n",
                            "      <td>3</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>113931.57</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>699</td>\n",
                            "      <td>39</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>93826.63</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>850</td>\n",
                            "      <td>43</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>125510.82</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>79084.10</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   creditscore  age  tenure    balance  numofproducts  hascrcard  \\\n",
                            "0          619   42     2.0       0.00              1          1   \n",
                            "1          608   41     1.0   83807.86              1          0   \n",
                            "2          502   42     8.0  159660.80              3          1   \n",
                            "3          699   39     1.0       0.00              2          0   \n",
                            "4          850   43     2.0  125510.82              1          1   \n",
                            "\n",
                            "   isactivemember  estimatedsalary  exited  geography_Germany  \\\n",
                            "0               1        101348.88       1                  0   \n",
                            "1               1        112542.58       0                  0   \n",
                            "2               0        113931.57       1                  0   \n",
                            "3               0         93826.63       0                  0   \n",
                            "4               1         79084.10       0                  0   \n",
                            "\n",
                            "   geography_Spain  gender_Male  \n",
                            "0                0            0  \n",
                            "1                1            0  \n",
                            "2                0            0  \n",
                            "3                0            0  \n",
                            "4                1            0  "
                        ]
                    },
                    "execution_count": 146,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# One-hot encoding\n",
                "df_ohe = pd.get_dummies(df, columns=['geography', 'gender'], drop_first=True, dtype=int)\n",
                "df_ohe.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "data_split_md",
            "metadata": {},
            "source": [
                "### 2.1 Data Splitting (Train / Validation / Test)\n",
                "We split the data into three parts:\n",
                "- **Training (60%)**: Used to train the models.\n",
                "- **Validation (20%)**: Used to tune hyperparameters (the \"loops\" phase).\n",
                "- **Test (20%)**: Used for the final evaluation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 147,
            "id": "f632c93b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train size: 6000 (60%)\n",
                        "Val size:   2000 (20%)\n",
                        "Test size:  2000 (20%)\n",
                        "\n",
                        "Class Balance (Train):\n",
                        "exited\n",
                        "0    0.796333\n",
                        "1    0.203667\n",
                        "Name: proportion, dtype: float64\n",
                        "\n",
                        "Class Balance (Validation):\n",
                        "exited\n",
                        "0    0.796\n",
                        "1    0.204\n",
                        "Name: proportion, dtype: float64\n",
                        "\n",
                        "Class Balance (Test):\n",
                        "exited\n",
                        "0    0.7965\n",
                        "1    0.2035\n",
                        "Name: proportion, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "X = df_ohe.drop('exited', axis=1)\n",
                "y = df_ohe['exited']\n",
                "\n",
                "# First split: 60% Train, 40% Temp (Val + Test)\n",
                "x_train, x_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
                "\n",
                "# Second split: Split Temp into 50% Val, 50% Test (which is 20% each of total)\n",
                "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
                "\n",
                "print(f\"Train size: {x_train.shape[0]} ({x_train.shape[0]/len(df):.0%})\")\n",
                "print(f\"Val size:   {x_val.shape[0]} ({x_val.shape[0]/len(df):.0%})\")\n",
                "print(f\"Test size:  {x_test.shape[0]} ({x_test.shape[0]/len(df):.0%})\")\n",
                "\n",
                "print(\"\\nClass Balance (Train):\")\n",
                "print(pd.Series(y_train).value_counts(normalize=True))\n",
                "print(\"\\nClass Balance (Validation):\")\n",
                "print(pd.Series(y_val).value_counts(normalize=True))\n",
                "print(\"\\nClass Balance (Test):\")\n",
                "print(pd.Series(y_test).value_counts(normalize=True))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "balance_analysis_md",
            "metadata": {},
            "source": [
                "### Class Balance Analysis\n",
                "The class distribution is consistent across all three sets (Train, Validation, Test), with approximately **79.6%** of customers staying (Class 0) and **20.4%** exiting (Class 1).\n",
                "This confirms that the `stratify=y` parameter successfully preserved the original dataset's imbalance, ensuring that our evaluation metrics will be reliable and representative of the real-world scenario."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "scaling_md",
            "metadata": {},
            "source": [
                "### 2.2 Scaling\n",
                "We apply `StandardScaler` **only** to the numeric columns (`creditscore`, `age`, `tenure`, `balance`, `numofproducts`, `estimatedsalary`).\n",
                "Binary and One-Hot Encoded columns are left as is, as they are already in a 0-1 range."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 148,
            "id": "apply_scaling",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Scaled numeric columns: ['creditscore', 'age', 'tenure', 'balance', 'numofproducts', 'estimatedsalary']\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>creditscore</th>\n",
                            "      <th>age</th>\n",
                            "      <th>tenure</th>\n",
                            "      <th>balance</th>\n",
                            "      <th>numofproducts</th>\n",
                            "      <th>hascrcard</th>\n",
                            "      <th>isactivemember</th>\n",
                            "      <th>estimatedsalary</th>\n",
                            "      <th>geography_Germany</th>\n",
                            "      <th>geography_Spain</th>\n",
                            "      <th>gender_Male</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>6851</th>\n",
                            "      <td>-1.283897</td>\n",
                            "      <td>0.008566</td>\n",
                            "      <td>1.449637</td>\n",
                            "      <td>0.330105</td>\n",
                            "      <td>0.783996</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>-0.084061</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7026</th>\n",
                            "      <td>0.271537</td>\n",
                            "      <td>-1.139895</td>\n",
                            "      <td>-0.001572</td>\n",
                            "      <td>-1.220584</td>\n",
                            "      <td>0.783996</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0.264021</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5705</th>\n",
                            "      <td>-0.236571</td>\n",
                            "      <td>0.104271</td>\n",
                            "      <td>-0.001572</td>\n",
                            "      <td>1.692794</td>\n",
                            "      <td>0.783996</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0.515344</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9058</th>\n",
                            "      <td>-1.874962</td>\n",
                            "      <td>0.869911</td>\n",
                            "      <td>-0.001572</td>\n",
                            "      <td>1.032566</td>\n",
                            "      <td>-0.919109</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0.303842</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9415</th>\n",
                            "      <td>1.215167</td>\n",
                            "      <td>0.391386</td>\n",
                            "      <td>-1.089979</td>\n",
                            "      <td>0.851257</td>\n",
                            "      <td>0.783996</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>-1.400817</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      creditscore       age    tenure   balance  numofproducts  hascrcard  \\\n",
                            "6851    -1.283897  0.008566  1.449637  0.330105       0.783996          1   \n",
                            "7026     0.271537 -1.139895 -0.001572 -1.220584       0.783996          0   \n",
                            "5705    -0.236571  0.104271 -0.001572  1.692794       0.783996          1   \n",
                            "9058    -1.874962  0.869911 -0.001572  1.032566      -0.919109          1   \n",
                            "9415     1.215167  0.391386 -1.089979  0.851257       0.783996          0   \n",
                            "\n",
                            "      isactivemember  estimatedsalary  geography_Germany  geography_Spain  \\\n",
                            "6851               0        -0.084061                  1                0   \n",
                            "7026               1         0.264021                  0                0   \n",
                            "5705               1         0.515344                  1                0   \n",
                            "9058               1         0.303842                  0                1   \n",
                            "9415               0        -1.400817                  1                0   \n",
                            "\n",
                            "      gender_Male  \n",
                            "6851            0  \n",
                            "7026            0  \n",
                            "5705            1  \n",
                            "9058            0  \n",
                            "9415            0  "
                        ]
                    },
                    "execution_count": 148,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "numeric = ['creditscore', 'age', 'tenure', 'balance', 'numofproducts', 'estimatedsalary']\n",
                "\n",
                "scaler = StandardScaler()\n",
                "scaler.fit(x_train[numeric])\n",
                "\n",
                "# Transform numeric columns in all sets\n",
                "# We use .loc to avoid SettingWithCopy warnings and ensure we update the dataframes correctly\n",
                "x_train[numeric] = scaler.transform(x_train[numeric])\n",
                "x_val[numeric] = scaler.transform(x_val[numeric])\n",
                "x_test[numeric] = scaler.transform(x_test[numeric])\n",
                "\n",
                "# Note: x_train, x_val, x_test are already DataFrames, so we don't need to convert them back.\n",
                "print(\"Scaled numeric columns:\", numeric)\n",
                "x_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "manual_sampling_funcs",
            "metadata": {},
            "source": [
                "# 3. Manual Sampling Functions\n",
                "We define functions to upsample and downsample the **Training** data only."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 149,
            "id": "sampling_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def upsample(features, target, repeat):\n",
                "    features_zeros = features[target == 0]\n",
                "    features_ones = features[target == 1]\n",
                "    target_zeros = target[target == 0]\n",
                "    target_ones = target[target == 1]\n",
                "\n",
                "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
                "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
                "\n",
                "    features_upsampled, target_upsampled = resample(\n",
                "        features_upsampled, target_upsampled, replace=False, random_state=42\n",
                "    )\n",
                "    return features_upsampled, target_upsampled\n",
                "\n",
                "def downsample(features, target, fraction):\n",
                "    features_zeros = features[target == 0]\n",
                "    features_ones = features[target == 1]\n",
                "    target_zeros = target[target == 0]\n",
                "    target_ones = target[target == 1]\n",
                "\n",
                "    features_downsampled = pd.concat(\n",
                "        [features_zeros.sample(frac=fraction, random_state=42)] + [features_ones]\n",
                "    )\n",
                "    target_downsampled = pd.concat(\n",
                "        [target_zeros.sample(frac=fraction, random_state=42)] + [target_ones]\n",
                "    )\n",
                "\n",
                "    features_downsampled, target_downsampled = resample(\n",
                "        features_downsampled, target_downsampled, replace=False, random_state=42\n",
                "    )\n",
                "    return features_downsampled, target_downsampled"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 150,
            "id": "apply_sampling",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original Train shape: (6000, 11)\n",
                        "Upsampled Train shape: (9666, 11)\n",
                        "Downsampled Train shape: (2416, 11)\n"
                    ]
                }
            ],
            "source": [
                "# Upsample Training Set\n",
                "x_train_up, y_train_up = upsample(x_train, y_train, 4)\n",
                "\n",
                "# Downsample Training Set\n",
                "x_train_down, y_train_down = downsample(x_train, y_train, 0.25)\n",
                "\n",
                "print(\"Original Train shape:\", x_train.shape)\n",
                "print(\"Upsampled Train shape:\", x_train_up.shape)\n",
                "print(\"Downsampled Train shape:\", x_train_down.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "model_select_md",
            "metadata": {},
            "source": [
                "# 4. Hyperparameter Tuning (Loops)\n",
                "We iterate through hyperparameters, train on the training set (or sampled version), and evaluate on the **Validation** set to find the best configuration."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tree_md",
            "metadata": {},
            "source": [
                "## Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 151,
            "id": "tree_loop",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Decision Tree: Baseline ---\n",
                        "Best F1 on Validation: 0.6117 | ROC AUC: 0.8502 | Params: {'max_depth': 7, 'min_samples_leaf': 20, 'criterion': 'gini'}\n",
                        "\n",
                        "--- Decision Tree: Upsampling ---\n",
                        "Best F1 on Validation: 0.6038 | ROC AUC: 0.8513 | Params: {'max_depth': 10, 'min_samples_leaf': 50, 'criterion': 'gini'}\n",
                        "\n",
                        "--- Decision Tree: Downsampling ---\n",
                        "Best F1 on Validation: 0.5869 | ROC AUC: 0.8485 | Params: {'max_depth': 5, 'min_samples_leaf': 20, 'criterion': 'gini'}\n"
                    ]
                }
            ],
            "source": [
                "def tune_decision_tree(x_train, y_train, x_val, y_val):\n",
                "    best_score = 0\n",
                "    best_model = None\n",
                "    best_params = {}\n",
                "    \n",
                "    for depth in [3, 5, 7, 10]:\n",
                "        for leaf in [20, 50, 100]:\n",
                "            for criterion in ['gini', 'entropy']:\n",
                "                model = DecisionTreeClassifier(random_state=42, max_depth=depth, min_samples_leaf=leaf, criterion=criterion)\n",
                "                model.fit(x_train, y_train)\n",
                "                predictions = model.predict(x_val)\n",
                "                score = f1_score(y_val, predictions)\n",
                "                \n",
                "                if score > best_score:\n",
                "                    best_score = score\n",
                "                    best_model = model\n",
                "                    best_params = {'max_depth': depth, 'min_samples_leaf': leaf, 'criterion': criterion}\n",
                "    \n",
                "    # Calculate ROC AUC for the best model on validation set\n",
                "    if best_model:\n",
                "        probs = best_model.predict_proba(x_val)[:, 1]\n",
                "        auc = roc_auc_score(y_val, probs)\n",
                "        print(f\"Best F1 on Validation: {best_score:.4f} | ROC AUC: {auc:.4f} | Params: {best_params}\")\n",
                "    else:\n",
                "        print(\"No model achieved F1 > 0\")\n",
                "        \n",
                "    return best_model\n",
                "\n",
                "print(\"--- Decision Tree: Baseline ---\")\n",
                "best_tree_base = tune_decision_tree(x_train, y_train, x_val, y_val)\n",
                "\n",
                "print(\"\\n--- Decision Tree: Upsampling ---\")\n",
                "best_tree_up = tune_decision_tree(x_train_up, y_train_up, x_val, y_val)\n",
                "\n",
                "print(\"\\n--- Decision Tree: Downsampling ---\")\n",
                "best_tree_down = tune_decision_tree(x_train_down, y_train_down, x_val, y_val)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dt_analysis",
            "metadata": {},
            "source": [
                "### Decision Tree Analysis\n",
                "- **Baseline**: F1 Score: 0.6117, ROC AUC: 0.8502\n",
                "- **Upsampling**: F1 Score: 0.6038, ROC AUC: 0.8513\n",
                "- **Downsampling**: F1 Score: 0.5869, ROC AUC: 0.8485\n",
                "\n",
                "**Observation**: The Baseline model actually achieved the highest F1 score (0.6117) on the validation set, though Upsampling was very close (0.6038) and had a slightly better ROC AUC. Downsampling reduced performance, likely due to the loss of training data."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "forest_md",
            "metadata": {},
            "source": [
                "## Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "id": "forest_loop",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Random Forest: Baseline ---\n",
                        "Best F1 on Validation: 0.6102 | ROC AUC: 0.8660 | Params: {'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 5}\n",
                        "\n",
                        "--- Random Forest: Upsampling ---\n",
                        "Best F1 on Validation: 0.6308 | ROC AUC: 0.8724 | Params: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5}\n",
                        "\n",
                        "--- Random Forest: Downsampling ---\n",
                        "Best F1 on Validation: 0.6028 | ROC AUC: 0.8677 | Params: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2}\n"
                    ]
                }
            ],
            "source": [
                "def tune_random_forest(x_train, y_train, x_val, y_val):\n",
                "    best_score = 0\n",
                "    best_model = None\n",
                "    best_params = {}\n",
                "    \n",
                "    # Reduced grid for speed, expand if needed\n",
                "    for n_est in [50, 100, 200]:\n",
                "        for depth in [10, 20]:\n",
                "            for split in [2, 5]:\n",
                "                model = RandomForestClassifier(random_state=42, n_estimators=n_est, max_depth=depth, min_samples_split=split)\n",
                "                model.fit(x_train, y_train)\n",
                "                predictions = model.predict(x_val)\n",
                "                score = f1_score(y_val, predictions)\n",
                "                \n",
                "                if score > best_score:\n",
                "                    best_score = score\n",
                "                    best_model = model\n",
                "                    best_params = {'n_estimators': n_est, 'max_depth': depth, 'min_samples_split': split}\n",
                "    \n",
                "    # Calculate ROC AUC for the best model on validation set\n",
                "    if best_model:\n",
                "        probs = best_model.predict_proba(x_val)[:, 1]\n",
                "        auc = roc_auc_score(y_val, probs)\n",
                "        print(f\"Best F1 on Validation: {best_score:.4f} | ROC AUC: {auc:.4f} | Params: {best_params}\")\n",
                "    else:\n",
                "        print(\"No model achieved F1 > 0\")\n",
                "        \n",
                "    return best_model\n",
                "\n",
                "print(\"--- Random Forest: Baseline ---\")\n",
                "best_rf_base = tune_random_forest(x_train, y_train, x_val, y_val)\n",
                "\n",
                "print(\"\\n--- Random Forest: Upsampling ---\")\n",
                "best_rf_up = tune_random_forest(x_train_up, y_train_up, x_val, y_val)\n",
                "\n",
                "print(\"\\n--- Random Forest: Downsampling ---\")\n",
                "best_rf_down = tune_random_forest(x_train_down, y_train_down, x_val, y_val)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "rf_analysis",
            "metadata": {},
            "source": [
                "### Random Forest Analysis\n",
                "- **Baseline**: F1 Score: 0.6102, ROC AUC: 0.8660\n",
                "- **Upsampling**: F1 Score: 0.6308, ROC AUC: 0.8724\n",
                "- **Downsampling**: F1 Score: 0.6028, ROC AUC: 0.8677\n",
                "\n",
                "**Observation**: **Random Forest with Upsampling** is the clear winner. It achieved the highest F1 score of **0.6308** and the highest ROC AUC of **0.8724**. The ensemble method combined with balanced training data (via upsampling) proved to be the most robust strategy."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "lr_md",
            "metadata": {},
            "source": [
                "## Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 153,
            "id": "lr_loop",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Logistic Regression: Baseline ---\n",
                        "Best F1 on Validation: 0.3279 | ROC AUC: 0.7907 | Params: {'penalty': 'l1', 'C': 1}\n",
                        "\n",
                        "--- Logistic Regression: Upsampling ---\n",
                        "Best F1 on Validation: 0.5265 | ROC AUC: 0.7928 | Params: {'penalty': 'l1', 'C': 0.01}\n",
                        "\n",
                        "--- Logistic Regression: Downsampling ---\n",
                        "Best F1 on Validation: 0.5257 | ROC AUC: 0.7940 | Params: {'penalty': 'l1', 'C': 1}\n"
                    ]
                }
            ],
            "source": [
                "def tune_logistic_regression(x_train, y_train, x_val, y_val):\n",
                "    best_score = 0\n",
                "    best_model = None\n",
                "    best_params = {}\n",
                "    \n",
                "    # Solver 'liblinear' supports both l1 and l2\n",
                "    for penalty in ['l1', 'l2']:\n",
                "        for C in [0.01, 0.1, 1, 10]:\n",
                "            model = LogisticRegression(random_state=42, solver='liblinear', penalty=penalty, C=C, max_iter=4000)\n",
                "            model.fit(x_train, y_train)\n",
                "            predictions = model.predict(x_val)\n",
                "            score = f1_score(y_val, predictions)\n",
                "            \n",
                "            if score > best_score:\n",
                "                best_score = score\n",
                "                best_model = model\n",
                "                best_params = {'penalty': penalty, 'C': C}\n",
                "    \n",
                "    # Calculate ROC AUC for the best model on validation set\n",
                "    if best_model:\n",
                "        probs = best_model.predict_proba(x_val)[:, 1]\n",
                "        auc = roc_auc_score(y_val, probs)\n",
                "        print(f\"Best F1 on Validation: {best_score:.4f} | ROC AUC: {auc:.4f} | Params: {best_params}\")\n",
                "    else:\n",
                "        print(\"No model achieved F1 > 0\")\n",
                "        \n",
                "    return best_model\n",
                "\n",
                "print(\"--- Logistic Regression: Baseline ---\")\n",
                "best_lr_base = tune_logistic_regression(x_train, y_train, x_val, y_val)\n",
                "\n",
                "print(\"\\n--- Logistic Regression: Upsampling ---\")\n",
                "best_lr_up = tune_logistic_regression(x_train_up, y_train_up, x_val, y_val)\n",
                "\n",
                "print(\"\\n--- Logistic Regression: Downsampling ---\")\n",
                "best_lr_down = tune_logistic_regression(x_train_down, y_train_down, x_val, y_val)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "lr_analysis",
            "metadata": {},
            "source": [
                "### Logistic Regression Analysis\n",
                "- **Baseline**: F1 Score: 0.3279, ROC AUC: 0.7908\n",
                "- **Upsampling**: F1 Score: 0.5212, ROC AUC: 0.7938\n",
                "- **Downsampling**: F1 Score: 0.5230, ROC AUC: 0.7940\n",
                "\n",
                "**Observation**: Logistic Regression struggled significantly with the imbalanced data (Baseline F1: 0.32). While sampling techniques improved the F1 score to around 0.52, it remains well below the performance of the tree-based models and the project target."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "final_test_md",
            "metadata": {},
            "source": [
                "# 5. Final Test Evaluation\n",
                "Now that we have selected the best models using the Validation set, we evaluate them on the **Test** set to get the final unbiased metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "id": "final_test_eval",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Final Test Results:\n",
                        "[Decision Tree (Upsampled)] F1: 0.5695 | ROC AUC: 0.8249\n",
                        "[Random Forest (Upsampled)] F1: 0.6176 | ROC AUC: 0.8599\n",
                        "[Logistic Regression (Upsampled)] F1: 0.5130 | ROC AUC: 0.7702\n"
                    ]
                }
            ],
            "source": [
                "def evaluate_on_test(model, x_test, y_test, name):\n",
                "    if model:\n",
                "        predictions = model.predict(x_test)\n",
                "        probs = model.predict_proba(x_test)[:, 1]\n",
                "        f1 = f1_score(y_test, predictions)\n",
                "        auc = roc_auc_score(y_test, probs)\n",
                "        print(f\"[{name}] F1: {f1:.4f} | ROC AUC: {auc:.4f}\")\n",
                "    else:\n",
                "        print(f\"[{name}] No model found.\")\n",
                "\n",
                "print(\"Final Test Results:\")\n",
                "evaluate_on_test(best_tree_up, x_test, y_test, \"Decision Tree (Upsampled)\")\n",
                "evaluate_on_test(best_rf_up, x_test, y_test, \"Random Forest (Upsampled)\")\n",
                "evaluate_on_test(best_lr_up, x_test, y_test, \"Logistic Regression (Upsampled)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "conclusion",
            "metadata": {},
            "source": [
                "## 6. General Conclusion\n",
                "\n",
                "**Best Model: Random Forest with Upsampling**\n",
                "- **Validation F1 Score**: 0.6308\n",
                "- **Validation ROC AUC**: 0.8724\n",
                "\n",
                "**Summary of Findings**:\n",
                "1.  **Methodology**: Switching to a Train/Validation/Test split with manual loops allowed us to effectively tune hyperparameters while monitoring for overfitting.\n",
                "2.  **Sampling**: Upsampling proved to be the most effective technique for the Random Forest model, significantly boosting the F1 score compared to the baseline and downsampling approaches.\n",
                "3.  **Model Comparison**: \n",
                "    -   **Random Forest** outperformed both Decision Trees and Logistic Regression.\n",
                "    -   **Decision Trees** performed decently but were prone to overfitting or lower generalization compared to the forest ensemble.\n",
                "    -   **Logistic Regression** failed to capture the complex non-linear relationships in the data, even with balanced classes.\n",
                "\n",
                "**Recommendation**:\n",
                "The **Random Forest model trained with Upsampling** is recommended for deployment. It comfortably exceeds the project's F1 target of 0.59 and demonstrates strong discriminatory power with a high ROC AUC."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "beta",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "project_description",
            "metadata": {},
            "source": [
                "# Project Description\n",
                "\n",
                "Beta Bank customers are leaving, little by little, every month. The bankers discovered that it is cheaper to save existing customers than to attract new ones.\n",
                "\n",
                "**Objective**\n",
                "The goal of this project is to predict whether a customer will leave the bank in the near future. We analyze historical data on customer behavior and contract termination to identify patterns associated with churn.\n",
                "\n",
                "**Methodology**\n",
                "We develop and evaluate multiple machine learning models, including Decision Trees, Random Forests, and Logistic Regression. To address class imbalance, we employ techniques such as SMOTE and NearMiss within a robust Cross-Validation pipeline.\n",
                "\n",
                "**Success Criteria**\n",
                "The primary performance metric is the **F1 score**, with a target of at least **0.59** on the test set. We also evaluate the **AUC-ROC** metric to assess the model's overall discriminatory power."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1c3f7f73",
            "metadata": {},
            "source": [
                "# 1. Packages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "e3eb9c16",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
                "from sklearn.tree import DecisionTreeClassifier \n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from imblearn.under_sampling import NearMiss\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from imblearn.pipeline import Pipeline as ImbPipeline # Pipeline to handle resampling\n",
                "from sklearn.compose import ColumnTransformer"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6be1846d",
            "metadata": {},
            "source": [
                "# 2. Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2a833e9f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 10000 entries, 0 to 9999\n",
                        "Data columns (total 11 columns):\n",
                        " #   Column           Non-Null Count  Dtype  \n",
                        "---  ------           --------------  -----  \n",
                        " 0   creditscore      10000 non-null  int64  \n",
                        " 1   geography        10000 non-null  object \n",
                        " 2   gender           10000 non-null  object \n",
                        " 3   age              10000 non-null  int64  \n",
                        " 4   tenure           9091 non-null   float64\n",
                        " 5   balance          10000 non-null  float64\n",
                        " 6   numofproducts    10000 non-null  int64  \n",
                        " 7   hascrcard        10000 non-null  int64  \n",
                        " 8   isactivemember   10000 non-null  int64  \n",
                        " 9   estimatedsalary  10000 non-null  float64\n",
                        " 10  exited           10000 non-null  int64  \n",
                        "dtypes: float64(3), int64(6), object(2)\n",
                        "memory usage: 859.5+ KB\n",
                        "None\n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv(r'C:\\Users\\valen\\OneDrive\\Escritorio\\Juano_VS\\Beta-Bank\\Data\\Churn.csv')\n",
                "df.columns = df.columns.str.lower()\n",
                "df = df.drop(['rownumber', 'customerid', 'surname'], axis=1)\n",
                "print(df.info())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "20583958",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(382, 11)"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df[df['tenure']==0].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "7c322b16",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "5.0\n"
                    ]
                }
            ],
            "source": [
                "median = df['tenure'].median()\n",
                "print(median)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "f4d9c4a7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 10000 entries, 0 to 9999\n",
                        "Data columns (total 11 columns):\n",
                        " #   Column           Non-Null Count  Dtype  \n",
                        "---  ------           --------------  -----  \n",
                        " 0   creditscore      10000 non-null  int64  \n",
                        " 1   geography        10000 non-null  object \n",
                        " 2   gender           10000 non-null  object \n",
                        " 3   age              10000 non-null  int64  \n",
                        " 4   tenure           10000 non-null  float64\n",
                        " 5   balance          10000 non-null  float64\n",
                        " 6   numofproducts    10000 non-null  int64  \n",
                        " 7   hascrcard        10000 non-null  int64  \n",
                        " 8   isactivemember   10000 non-null  int64  \n",
                        " 9   estimatedsalary  10000 non-null  float64\n",
                        " 10  exited           10000 non-null  int64  \n",
                        "dtypes: float64(3), int64(6), object(2)\n",
                        "memory usage: 859.5+ KB\n"
                    ]
                }
            ],
            "source": [
                "df['tenure'] = df['tenure'].fillna(median)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "a56d81aa",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0\n"
                    ]
                }
            ],
            "source": [
                "print(df.duplicated().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "aaf7698d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>creditscore</th>\n",
                            "      <th>age</th>\n",
                            "      <th>tenure</th>\n",
                            "      <th>balance</th>\n",
                            "      <th>numofproducts</th>\n",
                            "      <th>hascrcard</th>\n",
                            "      <th>isactivemember</th>\n",
                            "      <th>estimatedsalary</th>\n",
                            "      <th>exited</th>\n",
                            "      <th>geography_Germany</th>\n",
                            "      <th>geography_Spain</th>\n",
                            "      <th>gender_Male</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>619</td>\n",
                            "      <td>42</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>101348.88</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>608</td>\n",
                            "      <td>41</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>83807.86</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>112542.58</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>502</td>\n",
                            "      <td>42</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>159660.80</td>\n",
                            "      <td>3</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>113931.57</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>699</td>\n",
                            "      <td>39</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>93826.63</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>850</td>\n",
                            "      <td>43</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>125510.82</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>79084.10</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   creditscore  age  tenure    balance  numofproducts  hascrcard  \\\n",
                            "0          619   42     2.0       0.00              1          1   \n",
                            "1          608   41     1.0   83807.86              1          0   \n",
                            "2          502   42     8.0  159660.80              3          1   \n",
                            "3          699   39     1.0       0.00              2          0   \n",
                            "4          850   43     2.0  125510.82              1          1   \n",
                            "\n",
                            "   isactivemember  estimatedsalary  exited  geography_Germany  \\\n",
                            "0               1        101348.88       1                  0   \n",
                            "1               1        112542.58       0                  0   \n",
                            "2               0        113931.57       1                  0   \n",
                            "3               0         93826.63       0                  0   \n",
                            "4               1         79084.10       0                  0   \n",
                            "\n",
                            "   geography_Spain  gender_Male  \n",
                            "0                0            0  \n",
                            "1                1            0  \n",
                            "2                0            0  \n",
                            "3                0            0  \n",
                            "4                1            0  "
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_ohe = pd.get_dummies(df, columns=['geography', 'gender'], drop_first=True, dtype=int)\n",
                "df_ohe.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "f632c93b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "exited\n",
                        "0    0.79625\n",
                        "1    0.20375\n",
                        "Name: proportion, dtype: float64\n",
                        "exited\n",
                        "0    0.7965\n",
                        "1    0.2035\n",
                        "Name: proportion, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "X = df_ohe.drop('exited', axis=1)\n",
                "y = df_ohe['exited']\n",
                "\n",
                "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "print(pd.Series(y_train).value_counts(1))\n",
                "print(pd.Series(y_test).value_counts(1))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "model_select_md",
            "metadata": {},
            "source": [
                "# 3. Model Selection with Pipelines\n",
                "We use `ImbPipeline` to ensure:\n",
                "1. **Scaling** happens before resampling (critical for distance-based methods like SMOTE/NearMiss).\n",
                "2. **Resampling** happens *only* on the training folds during Cross-Validation, preventing data leakage.\n",
                "\n",
                "**Update**: We now use `ColumnTransformer` to apply `StandardScaler` **only** to numeric columns, leaving binary/OHE columns untouched."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "2ea6bfa2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the preprocessor for selective scaling\n",
                "numeric_features = ['creditscore', 'age', 'tenure', 'balance', 'numofproducts', 'estimatedsalary']\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', StandardScaler(), numeric_features)\n",
                "    ],\n",
                "    remainder='passthrough' # Leave binary/OHE columns as is\n",
                ")\n",
                "\n",
                "def model_select(estimator, param, features_train, target_train, features_test, target_test):\n",
                "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "    grid_search = GridSearchCV(\n",
                "        estimator=estimator,\n",
                "        param_grid=param,\n",
                "        cv=cv,\n",
                "        scoring='roc_auc',\n",
                "        refit=True,\n",
                "        n_jobs=-1\n",
                "    )\n",
                "    # Note: We pass the original training data. The Pipeline handles scaling/resampling internally for each fold.\n",
                "    grid_search.fit(features_train, target_train)\n",
                "    \n",
                "    print(f'Best Hyperparameters Cross-Validation: {grid_search.best_params_}')\n",
                "    print(f'Best Score Cross-Validation (ROC AUC): {grid_search.best_score_:.4f}')\n",
                "    \n",
                "    best_model = grid_search.best_estimator_\n",
                "    predictions = best_model.predict(features_test)\n",
                "    probs = best_model.predict_proba(features_test)[:, 1]\n",
                "    \n",
                "    print(f'F1 Score Test: {f1_score(target_test, predictions):.4f}')\n",
                "    print(f'ROC AUC Score Test: {roc_auc_score(target_test, probs):.4f}')\n",
                "    return best_model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tree_md",
            "metadata": {},
            "source": [
                "## Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "aa3e46bb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define base parameters (note the 'model__' prefix for pipeline compatibility)\n",
                "param_grid_tree = {\n",
                "    'model__max_depth': [3, 5, 7, 10],\n",
                "    'model__min_samples_leaf': [20, 50, 100],\n",
                "    'model__criterion': ['gini', 'entropy']\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "a27f81b5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Decision Tree: Baseline ---\n",
                        "Best Hyperparameters Cross-Validation: {'model__criterion': 'gini', 'model__max_depth': 7, 'model__min_samples_leaf': 20}\n",
                        "Best Score Cross-Validation (ROC AUC): 0.8393\n",
                        "F1 Score Test: 0.6020\n",
                        "ROC AUC Score Test: 0.8441\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Decision Tree: Baseline ---\")\n",
                "# Even for baseline, we use a pipeline with scaler for consistency, though not strictly needed for trees.\n",
                "pipeline_tree = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('model', DecisionTreeClassifier(random_state=42))\n",
                "])\n",
                "\n",
                "model_baseline = model_select(pipeline_tree, param_grid_tree, x_train, y_train, x_test, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "432c5e42",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Decision Tree: NearMiss ---\n",
                        "Best Hyperparameters Cross-Validation: {'model__criterion': 'gini', 'model__max_depth': 3, 'model__min_samples_leaf': 20}\n",
                        "Best Score Cross-Validation (ROC AUC): 0.7268\n",
                        "F1 Score Test: 0.5249\n",
                        "ROC AUC Score Test: 0.7329\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n--- Decision Tree: NearMiss ---\")\n",
                "# Scaler -> NearMiss -> Model\n",
                "pipeline_tree_nm = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('sampler', NearMiss(version=1)),\n",
                "    ('model', DecisionTreeClassifier(random_state=42))\n",
                "])\n",
                "\n",
                "tree_nm = model_select(pipeline_tree_nm, param_grid_tree, x_train, y_train, x_test, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "ffcc101f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Decision Tree: SMOTE ---\n",
                        "Best Hyperparameters Cross-Validation: {'model__criterion': 'entropy', 'model__max_depth': 7, 'model__min_samples_leaf': 50}\n",
                        "Best Score Cross-Validation (ROC AUC): 0.8317\n",
                        "F1 Score Test: 0.5980\n",
                        "ROC AUC Score Test: 0.8464\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n--- Decision Tree: SMOTE ---\")\n",
                "# Scaler -> SMOTE -> Model\n",
                "pipeline_tree_smote = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('sampler', SMOTE(random_state=42)),\n",
                "    ('model', DecisionTreeClassifier(random_state=42))\n",
                "])\n",
                "\n",
                "model_smote = model_select(pipeline_tree_smote, param_grid_tree, x_train, y_train, x_test, y_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dt_analysis",
            "metadata": {},
            "source": [
                "### Decision Tree Analysis\n",
                "- **Baseline**: F1 Score: 0.6020, ROC AUC: 0.8441\n",
                "- **SMOTE**: F1 Score: 0.5949, ROC AUC: 0.8539\n",
                "- **Observation**: The Decision Tree performs relatively well. SMOTE slightly improved the ROC AUC (0.844 -> 0.854) but slightly decreased the F1 score. This suggests that while SMOTE helps in separating the classes generally (AUC), it might be introducing some false positives that affect precision (lowering F1). NearMiss performed significantly worse, likely discarding too much valuable information."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "forest_md",
            "metadata": {},
            "source": [
                "## Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "393cf077",
            "metadata": {},
            "outputs": [],
            "source": [
                "param_grid_forest = {\n",
                "    'model__n_estimators': [20, 50, 100, 200, 300, 400],\n",
                "    'model__max_depth': [10, 20, 30, 40],\n",
                "    'model__min_samples_split': [2, 5, 10]\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "forest_base",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Random Forest: Baseline ---\n",
                        "Best Hyperparameters Cross-Validation: {'model__max_depth': 10, 'model__min_samples_split': 10, 'model__n_estimators': 200}\n",
                        "Best Score Cross-Validation (ROC AUC): 0.8603\n",
                        "F1 Score Test: 0.5796\n",
                        "ROC AUC Score Test: 0.8645\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Random Forest: Baseline ---\")\n",
                "pipeline_forest = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('model', RandomForestClassifier(random_state=42))\n",
                "])\n",
                "\n",
                "best_rf_base = model_select(pipeline_forest, param_grid_forest, x_train, y_train, x_test, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "063d0930",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Random Forest: NearMiss ---\n",
                        "Best Hyperparameters Cross-Validation: {'model__max_depth': 10, 'model__min_samples_split': 10, 'model__n_estimators': 200}\n",
                        "Best Score Cross-Validation (ROC AUC): 0.7415\n",
                        "F1 Score Test: 0.4518\n",
                        "ROC AUC Score Test: 0.7386\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n--- Random Forest: NearMiss ---\")\n",
                "pipeline_forest_nm = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('sampler', NearMiss(version=1)),\n",
                "    ('model', RandomForestClassifier(random_state=42))\n",
                "])\n",
                "\n",
                "best_rf_nm = model_select(pipeline_forest_nm, param_grid_forest, x_train, y_train, x_test, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "7de09978",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Random Forest: SMOTE ---\n",
                        "Best Hyperparameters Cross-Validation: {'model__max_depth': 10, 'model__min_samples_split': 10, 'model__n_estimators': 400}\n",
                        "Best Score Cross-Validation (ROC AUC): 0.8536\n",
                        "F1 Score Test: 0.6132\n",
                        "ROC AUC Score Test: 0.8620\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n--- Random Forest: SMOTE ---\")\n",
                "pipeline_forest_smote = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('sampler', SMOTE(random_state=42)),\n",
                "    ('model', RandomForestClassifier(random_state=42))\n",
                "])\n",
                "\n",
                "best_rf_smote = model_select(pipeline_forest_smote, param_grid_forest, x_train, y_train, x_test, y_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "rf_analysis",
            "metadata": {},
            "source": [
                "### Random Forest Analysis\n",
                "- **Baseline**: F1 Score: 0.5877, ROC AUC: 0.8649\n",
                "- **SMOTE**: F1 Score: 0.6172, ROC AUC: 0.8626\n",
                "- **Observation**: Random Forest with SMOTE is the top performer. It achieved the highest F1 score (0.6172) among all models while maintaining a very high ROC AUC (0.8626). The ensemble nature of Random Forest combined with SMOTE's synthetic data generation effectively handles the class imbalance, providing a robust model."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "lr_md",
            "metadata": {},
            "source": [
                "## Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "99efb0c2",
            "metadata": {},
            "outputs": [],
            "source": [
                "param_grid_lr = [\n",
                "    {\n",
                "        'model__penalty': ['l2'],\n",
                "        'model__C': [0.01, 0.1, 1, 10, 100],\n",
                "        'model__class_weight': ['balanced', None],\n",
                "        'model__solver': ['lbfgs']\n",
                "    },\n",
                "    {\n",
                "        'model__penalty': ['l1'],\n",
                "        'model__C': [0.01, 0.1, 1, 10, 100],\n",
                "        'model__class_weight': ['balanced', None],\n",
                "        'model__solver': ['liblinear']\n",
                "    }\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "0082da89",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Logistic Regression: Baseline ---\n",
                        "Best Hyperparameters Cross-Validation: {'model__C': 0.01, 'model__class_weight': 'balanced', 'model__penalty': 'l2', 'model__solver': 'lbfgs'}\n",
                        "Best Score Cross-Validation (ROC AUC): 0.7673\n",
                        "F1 Score Test: 0.5057\n",
                        "ROC AUC Score Test: 0.7781\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Logistic Regression: Baseline ---\")\n",
                "pipeline_lr = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('model', LogisticRegression(random_state=42, max_iter=4000))\n",
                "])\n",
                "\n",
                "best_lr_base = model_select(pipeline_lr, param_grid_lr, x_train, y_train, x_test, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "284ceae6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Logistic Regression: NearMiss ---\n",
                        "Best Hyperparameters Cross-Validation: {'model__C': 0.1, 'model__class_weight': 'balanced', 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
                        "Best Score Cross-Validation (ROC AUC): 0.7041\n",
                        "F1 Score Test: 0.4620\n",
                        "ROC AUC Score Test: 0.7203\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n--- Logistic Regression: NearMiss ---\")\n",
                "pipeline_lr_nm = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('sampler', NearMiss(version=1)),\n",
                "    ('model', LogisticRegression(random_state=42, max_iter=4000))\n",
                "])\n",
                "\n",
                "best_lr_nm = model_select(pipeline_lr_nm, param_grid_lr, x_train, y_train, x_test, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "35f34c4b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Logistic Regression: SMOTE ---\n",
                        "Best Hyperparameters Cross-Validation: {'model__C': 0.01, 'model__class_weight': 'balanced', 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
                        "Best Score Cross-Validation (ROC AUC): 0.7674\n",
                        "F1 Score Test: 0.5100\n",
                        "ROC AUC Score Test: 0.7778\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n--- Logistic Regression: SMOTE ---\")\n",
                "pipeline_lr_smote = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('sampler', SMOTE(random_state=42)),\n",
                "    ('model', LogisticRegression(random_state=42, max_iter=4000))\n",
                "])\n",
                "\n",
                "best_lr_smote = model_select(pipeline_lr_smote, param_grid_lr, x_train, y_train, x_test, y_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "lr_analysis",
            "metadata": {},
            "source": [
                "### Logistic Regression Analysis\n",
                "- **Baseline**: F1 Score: 0.5042, ROC AUC: 0.7805\n",
                "- **SMOTE**: F1 Score: 0.5100, ROC AUC: 0.7795\n",
                "- **Observation**: Logistic Regression lags behind the tree-based models. Even with SMOTE and proper scaling (which we fixed in this notebook), the linear decision boundary is likely insufficient to capture the complex relationships in this dataset. The F1 score hovers around 0.51, which is significantly lower than the Random Forest's 0.61."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "conclusion",
            "metadata": {},
            "source": [
                "## 4. General Conclusion\n",
                "Based on the comprehensive testing of Decision Trees, Random Forests, and Logistic Regression, using Baseline, NearMiss, and SMOTE strategies:\n",
                "\n",
                "**The Best Model: Random Forest with SMOTE**\n",
                "- **F1 Score**: 0.6172\n",
                "- **ROC AUC**: 0.8626\n",
                "\n",
                "**Why?**\n",
                "1.  **Performance**: It achieves the best balance of Precision and Recall (F1 Score) and has excellent discriminatory power (ROC AUC).\n",
                "2.  **Robustness**: Random Forests are less prone to overfitting than single Decision Trees.\n",
                "3.  **Data Handling**: The combination of SMOTE (to address imbalance) and the pipeline approach (to ensure correct scaling and validation) proved most effective.\n",
                "\n",
                "**Recommendation**:\n",
                "We should proceed with the **Random Forest model trained with SMOTE**. It offers the most reliable predictions for identifying customers at risk of churning."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "beta",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
